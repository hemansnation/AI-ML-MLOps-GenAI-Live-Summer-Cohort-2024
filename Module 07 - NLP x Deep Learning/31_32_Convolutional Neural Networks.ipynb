{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829b2739",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "we do not need to do feature engineering manually, it is done by the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6929941",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrains\n",
    "\n",
    "- you need huge data(100k samples - tabular data)\n",
    "- unstructured dataset(images, videos, audios, etc - greater than 50k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ef627",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artifical Neural Network\n",
    "\n",
    "1000x1000x1000 = 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dadcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## real world applications\n",
    "\n",
    "- image classification\n",
    "- facial recognition -> DCNN(Deep Convolutional Neural Networks)\n",
    "- object detection\n",
    "- medical image analysis - Xrays, MRIs\n",
    "- video analytics - action recognition\n",
    "- NLP - text classification, language translation, sentiment analysis(SpaCy, NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da931bfa",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dffc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "- convolution is a mathematical operation\n",
    "- the fundamental part of CNN is a filter(matrix)\n",
    "\n",
    "1*1 + 6*0 + 9*(-1) + 2*1 ,.... = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1e056",
   "metadata": {},
   "source": [
    "\n",
    "<img src='c1.png' />\n",
    "\n",
    "<br />\n",
    "\n",
    "<img src='c2.png' />\n",
    "\n",
    "<br />\n",
    "\n",
    "<img src='c4.png' />\n",
    "\n",
    "<br />\n",
    "\n",
    "<img src='c5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ea2a4",
   "metadata": {},
   "source": [
    "## what about colored image?\n",
    "\n",
    "<img src='c6.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "6x6x3 * 3x3x3 = 4x4x3\n",
    "\n",
    "3 is representing RGB - Red, Green, Blue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d842750",
   "metadata": {},
   "source": [
    "# Padding\n",
    "\n",
    "<img src='c7.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ea485",
   "metadata": {},
   "outputs": [],
   "source": [
    "in the convolutional operation the corner pixel will be used only once as compared to other pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f9732",
   "metadata": {},
   "source": [
    "<img src='c8.png' />\n",
    "\n",
    "# Apply padding\n",
    "\n",
    "<img src='c9.png' />\n",
    "\n",
    "# results\n",
    "\n",
    "<img src='c10.png' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dc3cb",
   "metadata": {},
   "source": [
    "# Stride\n",
    "\n",
    "<img src='c11.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "the above example - the stride is = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd588f6",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "\n",
    "<img src='c12.png' />\n",
    "\n",
    "# But Why\n",
    "\n",
    "<img src='c13.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling is used to reduce the image size and keep the features intact.\n",
    "\n",
    "where we are going to apply max pooling?\n",
    "- after convolutional layer\n",
    "\n",
    "best part about max pooling\n",
    "- no parameters(weights & bias) that means no training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a6b0c",
   "metadata": {},
   "source": [
    "# Fully Connected Layer\n",
    "\n",
    "<img src='c14.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FC layer -> dense network of neurons\n",
    "\n",
    "- applied after convolutional and max pooling layers\n",
    "- classify the output\n",
    "- associate features to a particular label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1e95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54064a40",
   "metadata": {},
   "source": [
    "# CNN Architecture\n",
    "\n",
    "<img src='c15.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation Function - help the model classify the label\n",
    "\n",
    "ReLU - Rectified Linear Unit\n",
    "\n",
    "- non-linearity to the model\n",
    "- the network is going to learn complex patterns and representations\n",
    "- computational efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a0e50",
   "metadata": {},
   "source": [
    "<img src='c16.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c8ad3",
   "metadata": {},
   "source": [
    "# Resources and Code\n",
    "\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks\n",
    "\n",
    "\n",
    "Code:\n",
    "https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/\n",
    "\n",
    "\n",
    "ReLU vs Sigmoid\n",
    "\n",
    "https://wandb.ai/ayush-thakur/dl-question-bank/reports/ReLU-vs-Sigmoid-Function-in-Deep-Neural-Networks--VmlldzoyMDk0MzI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4b9e2",
   "metadata": {},
   "source": [
    "Dataset: \n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba98fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "638a7db3",
   "metadata": {},
   "source": [
    "# Day 32 - CNN code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34ba6f",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "CNN with Cifar-10 DataSet - https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PyTorch\n",
    "\n",
    "- Deep Learning framework\n",
    "\n",
    "int(data structure in python) -> 4 bytes = 32 bits\n",
    "\n",
    "ndarray -> numpy\n",
    "\n",
    "in pytorch -> tensors(data strctures) ->(numerical values in matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febc6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all required imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# variables\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# where do you want to run your model? on GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ec556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:10<00:00, 2412424.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "\n",
    "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                                         std=[0.2023, 0.1994, 0.2010])\n",
    "                                    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                            train=True,\n",
    "                                            transform=all_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                           train=False,\n",
    "                                           transform=all_transforms,\n",
    "                                           download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eacfcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ea0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128,num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1) # flatten - to help the network run fast(1 dimensional)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fdc0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "model = ConvNeuralNet(num_classes)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                            weight_decay=0.005, momentum=0.9)\n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a122cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.8332\n",
      "Epoch [2/20], Loss: 1.4459\n",
      "Epoch [3/20], Loss: 1.0226\n",
      "Epoch [4/20], Loss: 0.6811\n",
      "Epoch [5/20], Loss: 1.1840\n",
      "Epoch [6/20], Loss: 1.2191\n",
      "Epoch [7/20], Loss: 1.3997\n",
      "Epoch [8/20], Loss: 0.8965\n",
      "Epoch [9/20], Loss: 0.6669\n",
      "Epoch [10/20], Loss: 1.5576\n",
      "Epoch [11/20], Loss: 0.7188\n",
      "Epoch [12/20], Loss: 0.6552\n",
      "Epoch [13/20], Loss: 0.6240\n",
      "Epoch [14/20], Loss: 1.1015\n",
      "Epoch [15/20], Loss: 0.6861\n",
      "Epoch [16/20], Loss: 0.8026\n",
      "Epoch [17/20], Loss: 0.7967\n",
      "Epoch [18/20], Loss: 0.6490\n",
      "Epoch [19/20], Loss: 0.5523\n",
      "Epoch [20/20], Loss: 0.7765\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass and optimizer\n",
    "        optimizer.zero_grad()  #set the gradient to zero before every update\n",
    "        loss.backward()        # calculate the new gradient\n",
    "        optimizer.step()       # update the weights\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf357281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 50000 train images = 83.048%\n"
     ]
    }
   ],
   "source": [
    "# training dataset \n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Accuracy on {} train images = {}%\".format(50000, 100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d0823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 10000 testing images = 68.8%\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Accuracy on {} testing images = {}%\".format(10000, 100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab62e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x23342b72850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3e1edf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 9, 1, 8, 5, 6, 9, 0, 6, 5, 6, 5, 7, 4, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d14f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 9, 1, 0, 5, 6, 9, 0, 4, 7, 6, 7, 5, 7, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9bfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf1036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ce60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
