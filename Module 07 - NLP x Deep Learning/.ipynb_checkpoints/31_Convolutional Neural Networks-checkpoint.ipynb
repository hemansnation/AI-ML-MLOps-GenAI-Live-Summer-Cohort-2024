{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c3c3d0",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "we do not need to do feature engineering manually, it is done by the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6929941",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrains\n",
    "\n",
    "- you need huge data(100k samples - tabular data)\n",
    "- unstructured dataset(images, videos, audios, etc - greater than 50k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ef627",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artifical Neural Network\n",
    "\n",
    "1000x1000x1000 = 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dadcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## real world applications\n",
    "\n",
    "- image classification\n",
    "- facial recognition -> DCNN(Deep Convolutional Neural Networks)\n",
    "- object detection\n",
    "- medical image analysis - Xrays, MRIs\n",
    "- video analytics - action recognition\n",
    "- NLP - text classification, language translation, sentiment analysis(SpaCy, NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da931bfa",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dffc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "- convolution is a mathematical operation\n",
    "- the fundamental part of CNN is a filter(matrix)\n",
    "\n",
    "1*1 + 6*0 + 9*(-1) + 2*1 ,.... = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1e056",
   "metadata": {},
   "source": [
    "\n",
    "<img src='c1.png' />\n",
    "\n",
    "<br />\n",
    "\n",
    "<img src='c2.png' />\n",
    "\n",
    "<br />\n",
    "\n",
    "<img src='c4.png' />\n",
    "\n",
    "<br />\n",
    "\n",
    "<img src='c5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ea2a4",
   "metadata": {},
   "source": [
    "## what about colored image?\n",
    "\n",
    "<img src='c6.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "6x6x3 * 3x3x3 = 4x4x3\n",
    "\n",
    "3 is representing RGB - Red, Green, Blue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d842750",
   "metadata": {},
   "source": [
    "# Padding\n",
    "\n",
    "<img src='c7.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ea485",
   "metadata": {},
   "outputs": [],
   "source": [
    "in the convolutional operation the corner pixel will be used only once as compared to other pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f9732",
   "metadata": {},
   "source": [
    "<img src='c8.png' />\n",
    "\n",
    "# Apply padding\n",
    "\n",
    "<img src='c9.png' />\n",
    "\n",
    "# results\n",
    "\n",
    "<img src='c10.png' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dc3cb",
   "metadata": {},
   "source": [
    "# Stride\n",
    "\n",
    "<img src='c11.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "the above example - the stride is = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd588f6",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "\n",
    "<img src='c12.png' />\n",
    "\n",
    "# But Why\n",
    "\n",
    "<img src='c13.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling is used to reduce the image size and keep the features intact.\n",
    "\n",
    "where we are going to apply max pooling?\n",
    "- after convolutional layer\n",
    "\n",
    "best part about max pooling\n",
    "- no parameters(weights & bias) that means no training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a6b0c",
   "metadata": {},
   "source": [
    "# Fully Connected Layer\n",
    "\n",
    "<img src='c14.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FC layer -> dense network of neurons\n",
    "\n",
    "- applied after convolutional and max pooling layers\n",
    "- classify the output\n",
    "- associate features to a particular label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1e95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54064a40",
   "metadata": {},
   "source": [
    "# CNN Architecture\n",
    "\n",
    "<img src='c15.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation Function - help the model classify the label\n",
    "\n",
    "ReLU - Rectified Linear Unit\n",
    "\n",
    "- non-linearity to the model\n",
    "- the network is going to learn complex patterns and representations\n",
    "- computational efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a0e50",
   "metadata": {},
   "source": [
    "<img src='c16.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c8ad3",
   "metadata": {},
   "source": [
    "# Resources and Code\n",
    "\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks\n",
    "\n",
    "\n",
    "Code:\n",
    "https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/\n",
    "\n",
    "\n",
    "ReLU vs Sigmoid\n",
    "\n",
    "https://wandb.ai/ayush-thakur/dl-question-bank/reports/ReLU-vs-Sigmoid-Function-in-Deep-Neural-Networks--VmlldzoyMDk0MzI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4365e2",
   "metadata": {},
   "source": [
    "Dataset: \n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba98fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9ccca0c",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "CNN with Cifar-10 DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all required imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# variables\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# where do you want to run your model? on GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe097f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                                         std=[0.2023, 0.1994, 0.2010])\n",
    "                                    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                            train=True,\n",
    "                                            transform=all_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                           train=False,\n",
    "                                           transform=all_transforms,\n",
    "                                           download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b3395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50356ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128,num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d54422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "model = ConvNeuralNet(num_classes)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                            weight_decay=0.005, momentum=0.9)\n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ca4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trianing\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass and optimizer\n",
    "        optimizer.zero_grad()  #set the gradient to zero before every update\n",
    "        loss.backward()        # calculate the new gradient\n",
    "        optimizer.step()       # update the weights\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Accuracy on {} train images = {}%\".format(50000, 100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87ff6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29cc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
