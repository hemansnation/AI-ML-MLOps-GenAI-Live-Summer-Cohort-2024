{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce21813",
   "metadata": {},
   "source": [
    "# Recurrent(Feedback) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation \n",
    "- Google Translate\n",
    "- Apple siri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1365e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequential data\n",
    "\n",
    "this is a sweet apple.\n",
    "\n",
    "\n",
    "- nlp task\n",
    "- speech recognition\n",
    "- time-series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715173f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memorize parts of the inputs and use them to make accurate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba2d7c",
   "metadata": {},
   "source": [
    "## Feed Forward Network\n",
    "\n",
    "\n",
    "<img src='r1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd4dcb",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "<img src='r2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0743c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "                this is a red......{apple}\n",
    "encoding -> one-hot encoding\n",
    "\n",
    "0 - a           \n",
    "1 - are\n",
    "2 - apple\n",
    "3\n",
    ".\n",
    ".\n",
    ".\n",
    "4100 - this\n",
    ".\n",
    ".\n",
    "10000 - ...\n",
    "\n",
    "\n",
    "GPT3 -> 500+Billion words(tokens) -> 175Billion parameters\n",
    "\n",
    "word embeddings -> word2vec, GloVe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aea5b4",
   "metadata": {},
   "source": [
    "## RNN steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - Input a dataset\n",
    "2 - complex computation - randomly initialise variables(weights and biases)\n",
    "\n",
    "y => f(x) = Wx + b\n",
    "\n",
    "3 - generating predictions\n",
    "4 - capare the predictions with expected values => error\n",
    "5 - propagating the error back to the same path in the network and adjust the variables\n",
    "\n",
    "6 - repeat 1 - 5 until we have optimum variables\n",
    "7 - prediction is made on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ceab30",
   "metadata": {},
   "source": [
    "# Formula\n",
    "\n",
    "<img src='r3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - holds the information about the previous words in the sequence\n",
    "h0 -> will initially be zero\n",
    "\n",
    "f() -> activation function -> tanh or sigmoid or softmax\n",
    "\n",
    "2 - calculate the predicted word vector, we use softmax to produce vector\n",
    "(v,1) => probability distribution give you index of the most likely next word.\n",
    "\n",
    "3 - cross entropy - loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305fa88",
   "metadata": {},
   "source": [
    "# problems with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - exploding gradients\n",
    "- large weights updates\n",
    "\n",
    "2 - vanishing gradients\n",
    "- gradient will goes to zero\n",
    "\n",
    "\n",
    "cause\n",
    "\n",
    "1 - chain in multiplication\n",
    "2 - long sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c17bee",
   "metadata": {},
   "source": [
    "# RNN Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - Bidirectional RNN\n",
    "2 - Gated Recurrent Unit (GRU)\n",
    "3 - Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c4d29",
   "metadata": {},
   "source": [
    "# Implementation using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda46ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1074e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "047cf2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RNN\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out, _ = self.rnn(x)\n",
    "        \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59561b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "output_size = 10   # number of classes (0-9 digits)\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff06751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:04<00:00, 2376027.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 129642.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:03<00:00, 542429.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2267920.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06dc252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data loaders\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d607b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss function, optimizer\n",
    "\n",
    "model = SimpleRNN(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b8fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images, labels = images.view(-1, 28, 28).to(device), labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # loss calculation\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}'.format(epoch, num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9cd1d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 95.75%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.view(-1, 28, 28).to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Accuracy on the test set: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf726f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f8e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6694ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
