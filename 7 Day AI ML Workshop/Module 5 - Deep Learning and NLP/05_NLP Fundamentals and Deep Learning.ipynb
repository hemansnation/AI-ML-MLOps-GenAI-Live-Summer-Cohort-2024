{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2c3e42",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f209c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "A -> 65 -> binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ae65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "your tshirt is killer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "- intent\n",
    "- context\n",
    "\n",
    "Himanshu is here. He is sitting on a chair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db8472",
   "metadata": {},
   "source": [
    "# NLP basics\n",
    "https://newsletter.himanshuramchandani.co/p/5-alarming-things-you-must-know-about-generativeai-as-a-leader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efb930",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "<img src='n1.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "the cat sat on the mat -> [2,1,0,1,1,1]\n",
    "the dog sat on the cat -> [2,1,1,1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84ecf8",
   "metadata": {},
   "source": [
    "# Sequential Representation\n",
    "\n",
    "<img src='n2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1,2,3,4],[5,6,7,8]]\n",
    "\n",
    "while i<5:\n",
    "    while i<5:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3987977",
   "metadata": {},
   "outputs": [],
   "source": [
    "O(n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a84d8",
   "metadata": {},
   "source": [
    "# PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c77359",
   "metadata": {},
   "outputs": [],
   "source": [
    "- deep learning framework - harware acceleration(GPUs)\n",
    "- dynamic computational graphs(data structure - Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fa690",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT3 - trained 175B parameters\n",
    "\n",
    "dataset -> 500B tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3542bf1",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "<img src='n3.png' />\n",
    "\n",
    "<img src='Tensors.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae28f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e89c379d",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "<img src='n2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f841c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47397338",
   "metadata": {},
   "source": [
    "# Global Vector for Word Embeddings\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6120c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(path):\n",
    "    file = open(path, 'r', encoding='utf8')\n",
    "    model = {}\n",
    "    \n",
    "    for l in file:\n",
    "        line = l.split()\n",
    "        word = line[0]\n",
    "        value = np.array([float(val) for val in line[1:]])\n",
    "        model[word] = value\n",
    "    \n",
    "    return model\n",
    "\n",
    "glove = loadGlove('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93e04d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
       "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
       "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
       "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
       "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
       "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
       "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
       "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
       "       -0.93256 , -0.15025 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python']   # vector embedding for the word Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca403005",
   "metadata": {},
   "source": [
    "## How the system know that these words are similar?\n",
    "\n",
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a326f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbfb9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92180053]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['dog'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c7f6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19825255]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['piano'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a41e0508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7839043]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['king'].reshape(1,-1), glove['queen'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f63ffe1",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a795c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b98458",
   "metadata": {},
   "source": [
    "# RNN - Recurrent(Feedback) Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c59f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention Mechanism\n",
    "\n",
    "Himanshu is here. He is sitting on a chair. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2070dd7",
   "metadata": {},
   "source": [
    "# Problems with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "- forward pass - sort-term memory\n",
    "- backward pass - vanishing gradient problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b32da",
   "metadata": {},
   "source": [
    "# RNN Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01409eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - Bidirectional RNN  (BRNN)\n",
    "2 - Gated Recurrent Unit (GRU)\n",
    "3 - Long Short Term Memory(LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f859a",
   "metadata": {},
   "source": [
    "# Long Short Term Memory(LSTM)\n",
    "\n",
    "<img src='l2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8806477",
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanism -> gates\n",
    "- it stores relevant information to make predictions\n",
    "\n",
    "RNN\n",
    "- words -> vectors -> RNN process it one-by-one -> tanh[-1, 1] -> hidden layer \n",
    "\n",
    "[5,0.1,-0.5] -> tanh -> [0.99, 0.009, -0.46]\n",
    "\n",
    "- small sentences, \n",
    "- less computational as compared to LSTM and GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de01782",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "<img src='t8.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer use attention to boost the speed, more specifically self-attention\n",
    "\n",
    "attention -> assign different weights to the input sequence, based on relevant parts\n",
    "\n",
    "self-attention -> intra-attention/inner attention\n",
    "                it will assign weigths based on the importance of each element \n",
    "                in relation to other within the same sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7c0d9",
   "metadata": {},
   "source": [
    "# Deep Learning Interview Questions\n",
    "\n",
    "https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Deep%20Learning%20Questions%20&%20Answers%20for%20Data%20Scientists.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71202bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
